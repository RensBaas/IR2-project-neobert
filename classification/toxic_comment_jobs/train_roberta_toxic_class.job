#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=roberta_toxic_class
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=2
#SBATCH --time=4:00:00
#SBATCH --output=logs/train_roberta_toxic_%j.out
#SBATCH --error=logs/train_roberta_toxic_%j.err

module load 2025

pip install --user transformers datasets accelerate xformers

# Set cache directories
export HF_HOME=$HOME/.cache/huggingface
export TRANSFORMERS_CACHE=$HOME/.cache/huggingface/transformers
export HF_DATASETS_CACHE=$HOME/.cache/huggingface/datasets

export TRUST_REMOTE_CODE=True

# Create output directory 
mkdir -p $HOME/trained_models
mkdir -p logs

# Print some info
echo "Job started at: $(date)"
echo "Running on node: $(hostname)"
echo "GPU info:"
nvidia-smi

# Run training
python $HOME/bert_classification_toxic.py \
  --model_name FacebookAI/roberta-base \
  --save_name roberta-base \
  --dataset_name train.csv

echo "Job finished at: $(date)"
